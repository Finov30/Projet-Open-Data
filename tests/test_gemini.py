"""
Test de configuration Gemini pour NutriScan.
Ex√©cutez ce fichier pour v√©rifier que votre cl√© API fonctionne.
"""

import os
import sys
from dotenv import load_dotenv

def test_env_loading():
    """Test 1 : V√©rifier que le fichier .env est charg√©."""
    print("=" * 60)
    print("TEST 1 : Chargement du fichier .env")
    print("=" * 60)
    
    load_dotenv()
    
    api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key:
        print("‚ùå √âCHEC : La cl√© GEMINI_API_KEY n'est pas trouv√©e dans .env")
        print("\nV√©rifiez que :")
        print("  1. Le fichier .env existe dans le dossier racine")
        print("  2. Il contient : GEMINI_API_KEY=votre_cle")
        print("  3. La cl√© commence par 'AIzaSy'")
        return False
    
    if not api_key.startswith("AIzaSy"):
        print(f"‚ö†Ô∏è  ATTENTION : La cl√© ne semble pas valide")
        print(f"   Format actuel : {api_key[:10]}...")
        print(f"   Format attendu : AIzaSy...")
        return False
    
    print(f"‚úÖ SUCC√àS : Cl√© API trouv√©e")
    print(f"   Pr√©fixe : {api_key[:10]}...")
    print(f"   Longueur : {len(api_key)} caract√®res")
    return True


def test_litellm_import():
    """Test 2 : V√©rifier que LiteLLM est install√©."""
    print("\n" + "=" * 60)
    print("TEST 2 : Import de LiteLLM")
    print("=" * 60)
    
    try:
        import litellm
        print(f"‚úÖ SUCC√àS : LiteLLM version {litellm.__version__}")
        return True
    except ImportError:
        print("‚ùå √âCHEC : LiteLLM n'est pas install√©")
        print("\nInstallez-le avec :")
        print("  uv add litellm google-generativeai")
        print("  # ou")
        print("  pip install litellm google-generativeai")
        return False


def test_gemini_connection():
    """Test 3 : Tester la connexion √† l'API Gemini."""
    print("\n" + "=" * 60)
    print("TEST 3 : Connexion √† l'API Gemini")
    print("=" * 60)
    
    try:
        import litellm
        
        print("Envoi d'une requ√™te de test √† Gemini Flash...")
        
        response = litellm.completion(
            model="gemini/gemini-1.5-flash",
            messages=[
                {"role": "user", "content": "R√©ponds simplement 'OK' si tu me re√ßois"}
            ],
            max_tokens=10
        )
        
        result = response.choices[0].message.content
        
        print(f"‚úÖ SUCC√àS : Connexion √©tablie")
        print(f"   R√©ponse de Gemini : {result}")
        return True
        
    except Exception as e:
        print(f"‚ùå √âCHEC : Erreur de connexion")
        print(f"   Erreur : {str(e)}")
        
        if "API_KEY_INVALID" in str(e):
            print("\nüí° Solution : Votre cl√© API n'est pas valide")
            print("   1. Allez sur https://aistudio.google.com/app/apikey")
            print("   2. Cr√©ez une nouvelle cl√©")
            print("   3. Mettez √† jour votre fichier .env")
        
        elif "quota" in str(e).lower():
            print("\nüí° Solution : Quota d√©pass√©")
            print("   1. Attendez 24h (reset quotidien)")
            print("   2. Ou cr√©ez un nouveau projet Google Cloud")
        
        else:
            print("\nüí° V√©rifiez votre connexion internet")
        
        return False


def test_module_ia():
    """Test 4 : Tester le module IA de NutriScan."""
    print("\n" + "=" * 60)
    print("TEST 4 : Module IA NutriScan")
    print("=" * 60)
    
    try:
        from src.ia import LLMManager, ProductAnalyzer
        
        print("‚úÖ Import du module IA r√©ussi")
        
        # Test LLMManager
        print("\nTest du LLMManager...")
        llm = LLMManager()
        
        response = llm.complete(
            messages=[{"role": "user", "content": "Dis bonjour"}],
            model="gemini/gemini-1.5-flash",
            max_tokens=20
        )
        
        print(f"‚úÖ LLMManager fonctionne")
        print(f"   R√©ponse : {response[:50]}...")
        
        # Test ProductAnalyzer
        print("\nTest du ProductAnalyzer...")
        analyzer = ProductAnalyzer(llm)
        
        test_product = {
            "product_name": "Test Product",
            "nutriscore_grade": "a",
            "nova_group": 1,
            "energy_100g": 200,
            "sugars_100g": 5,
            "fat_100g": 3,
            "salt_100g": 0.1
        }
        
        result = analyzer.analyze_product(test_product, model="gemini/gemini-1.5-flash")
        
        if result["success"]:
            print(f"‚úÖ ProductAnalyzer fonctionne")
            print(f"   Analyse g√©n√©r√©e : {len(result['analysis'])} caract√®res")
            print(f"   Score calcul√© : {result['scores']['overall_health']}/100")
        else:
            print(f"‚ö†Ô∏è  ProductAnalyzer a retourn√© une erreur : {result.get('error')}")
            return False
        
        return True
        
    except ImportError as e:
        print(f"‚ùå √âCHEC : Impossible d'importer le module IA")
        print(f"   Erreur : {e}")
        print("\nüí° V√©rifiez que les fichiers du module IA sont dans src/ia/")
        return False
    
    except Exception as e:
        print(f"‚ùå √âCHEC : Erreur lors du test")
        print(f"   Erreur : {e}")
        return False


def test_models_availability():
    """Test 5 : V√©rifier les mod√®les disponibles."""
    print("\n" + "=" * 60)
    print("TEST 5 : Mod√®les disponibles")
    print("=" * 60)
    
    try:
        from src.ia import LLMManager
        
        models = LLMManager.get_available_models()
        
        print(f"‚úÖ {len(models)} mod√®les configur√©s :\n")
        
        for model_name, model_info in models.items():
            icon = "üü¢" if "gemini" in model_name else "üîµ"
            print(f"{icon} {model_name}")
            print(f"   Provider: {model_info['provider']}")
            print(f"   Description: {model_info['description']}")
            print()
        
        return True
        
    except Exception as e:
        print(f"‚ùå √âCHEC : {e}")
        return False


def run_all_tests():
    """Ex√©cute tous les tests dans l'ordre."""
    print("\n")
    print("üß™ " + "=" * 58)
    print("üß™ TEST DE CONFIGURATION GEMINI - NUTRISCAN")
    print("üß™ " + "=" * 58)
    print()
    
    tests = [
        ("Chargement .env", test_env_loading),
        ("Import LiteLLM", test_litellm_import),
        ("Connexion Gemini", test_gemini_connection),
        ("Module IA", test_module_ia),
        ("Mod√®les disponibles", test_models_availability)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n‚ùå Erreur inattendue dans {test_name}: {e}")
            results.append((test_name, False))
    
    # R√©sum√©
    print("\n" + "=" * 60)
    print("R√âSUM√â DES TESTS")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} - {test_name}")
    
    print("\n" + "=" * 60)
    print(f"R√©sultat : {passed}/{total} tests r√©ussis")
    print("=" * 60)
    
    if passed == total:
        print("\nüéâ F√âLICITATIONS ! Votre configuration est parfaite !")
        print("Vous pouvez maintenant utiliser le module IA avec Gemini.")
        print("\nProchaines √©tapes :")
        print("  1. Lancez les exemples : python example_usage.py")
        print("  2. Int√©grez avec Streamlit")
        print("  3. Committez sur GitHub")
        return 0
    else:
        print("\n‚ö†Ô∏è  Certains tests ont √©chou√©.")
        print("Consultez les messages d'erreur ci-dessus pour r√©soudre les probl√®mes.")
        print("\nAide disponible :")
        print("  - README_IA.md : Documentation compl√®te")
        print("  - Guide Gemini : Instructions d√©taill√©es")
        return 1


if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)